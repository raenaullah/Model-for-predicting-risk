{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pprint, copy, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "from theano import shared\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler\n",
    "from typing import Set, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \"\"\"Pipeline to preprocess tabular IID data ready for input to a binary\n",
    "        classification model.\n",
    "\n",
    "        After instantiation, run the fit_transform() method on the training\n",
    "        data, then use the transform() method to preprocess subsequent data.\n",
    "\n",
    "        I deliberately avoid making the data an attribute of the class. This\n",
    "        means that we have to pass the DataFrame between functions a lot, but\n",
    "        it should make pickling the fitted preprocessor object more\n",
    "        practical.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 continuous_scaler=StandardScaler,\n",
    "                 continuous_fill_value: float = 0.0,\n",
    "                 categorical_fill_value: str = 'MISSING',\n",
    "                 verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            continuous_fill_value: Value to replace missing values in continuous\n",
    "                variables with, after scaling\n",
    "            categorical_fill_value: Value to replace missing values in\n",
    "                categorical variables with\n",
    "            verbose: If True, prints reports on some parts of the preprocessing\n",
    "        \"\"\"\n",
    "        self.continuous_scaler = continuous_scaler\n",
    "        self.continuous_fill_value = continuous_fill_value\n",
    "        self.categorical_fill_value = categorical_fill_value\n",
    "        self.verbose = verbose\n",
    "        self.y_name = None\n",
    "        self.x_names = None\n",
    "        self.force_categorical = None\n",
    "        self.columns = None\n",
    "        self.col_i = None\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit_transform(self,\n",
    "                      df: pd.DataFrame,\n",
    "                      y_name: str,\n",
    "                      force_categorical: Set[str] = set()) -> Tuple[np.ndarray,\n",
    "                                                                    np.ndarray]:\n",
    "        \"\"\"Transforms a table of training data ready for input to a binary\n",
    "            classification model. Fits encoders for continuous and categorical\n",
    "            variables in the process.\n",
    "\n",
    "        Args:\n",
    "            df: Rows are samples, columns are features. May contain missing\n",
    "                values.\n",
    "            y_name: Name of column (in df) containing the binary labels\n",
    "            force_categorical: Column names for continuous variables to encode\n",
    "                as categorical\n",
    "\n",
    "        Returns:\n",
    "            (features, binary labels)\n",
    "        \"\"\"\n",
    "        self.y_name = y_name\n",
    "        self.force_categorical = force_categorical\n",
    "        df = df.reset_index(drop=True)\n",
    "        self._set_columns(df)\n",
    "        self._force_continuous_to_categorical()\n",
    "        self._remove_y_from_categorical()\n",
    "        df = self._drop_where_label_missing(df)\n",
    "        df = self._fit_transform_continuous(df)\n",
    "        df = self._make_continuous_missingness_indicators(df)\n",
    "        df = self._impute_continuous_missingness(df)\n",
    "        df = self._cast_categorical_as_str(df)\n",
    "        df = self._add_missingness_category_for_categorical(df)\n",
    "        df = self._fit_transform_all_categorical(df)\n",
    "        self._set_x_names(df)\n",
    "        self._set_col_i()\n",
    "        df = self._fit_transform_y(df)\n",
    "        return df[self.x_names].values, df[self.y_name].values\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Transforms (using already-fitted encoders) table of new data ready\n",
    "            for input to a binary classification model.\n",
    "\n",
    "        Args:\n",
    "            df: Rows are samples, columns are features. Must match the format of\n",
    "                the DataFrame passed to fit_transform() earlier. May contain\n",
    "                missing values.\n",
    "\n",
    "        Returns:\n",
    "            (features, binary labels)\n",
    "        \"\"\"\n",
    "        df = df.reset_index(drop=True)\n",
    "        self._pre_transform_sanity_check(df)\n",
    "        df = self._drop_where_label_missing(df)\n",
    "        df = self._transform_continuous(df)\n",
    "        df = self._make_continuous_missingness_indicators(df)\n",
    "        df = self._impute_continuous_missingness(df)\n",
    "        df = self._cast_categorical_as_str(df)\n",
    "        df = self._add_missingness_category_for_categorical(df)\n",
    "        df = self._transform_all_categorical(df)\n",
    "        df = self._transform_y(df)\n",
    "        return df[self.x_names].values, df[self.y_name].values\n",
    "\n",
    "    def _pre_transform_sanity_check(self, df: pd.DataFrame):\n",
    "        # TODO: Add some tests here\n",
    "        pass\n",
    "\n",
    "    def _set_columns(self, df: pd.DataFrame):\n",
    "        \"\"\"Divides DataFrame column names into categorical and continuous.\"\"\"\n",
    "        self.columns = {'cat': df.select_dtypes(\n",
    "                            include=['object']).columns.tolist(),\n",
    "                        'cont': df.select_dtypes(\n",
    "                            exclude=['object']).columns.tolist()}\n",
    "\n",
    "    def _force_continuous_to_categorical(self):\n",
    "        \"\"\"Forces categorical encoding of specified continuous variables.\"\"\"\n",
    "        for feature in self.force_categorical:\n",
    "            self.columns['cont'].remove(feature)\n",
    "            self.columns['cat'].append(feature)\n",
    "\n",
    "    def _remove_y_from_categorical(self):\n",
    "        \"\"\"Removes y_name from self.columns['cat'] to avoid inappropriate\n",
    "            processing as a categorical feature.\"\"\"\n",
    "        self.columns['cat'].remove(self.y_name)\n",
    "\n",
    "    def _drop_where_label_missing(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Drops any rows in the data where the label is missing.\"\"\"\n",
    "        pre_drop_size = df.shape[0]\n",
    "        df = df.dropna(subset=[self.y_name])\n",
    "        n_dropped = pre_drop_size - df.shape[0]\n",
    "        if n_dropped and self.verbose:\n",
    "            print('Dropped {} rows where label missing.'.format(n_dropped))\n",
    "        return df\n",
    "\n",
    "    def _fit_transform_continuous(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fits encoders for non-missing values of continuous variables, and\n",
    "            scales them. Casts to float64.\"\"\"\n",
    "        self.encoders['scalers'] = dict()\n",
    "        for col_name in self.columns['cont']:\n",
    "            self.encoders['scalers'][col_name] = self.continuous_scaler()\n",
    "            df.loc[df[col_name].notnull(), col_name] = self.encoders[\n",
    "                'scalers'][col_name].fit_transform(df.loc[\n",
    "                    df[col_name].notnull(),\n",
    "                    col_name].values.reshape(-1, 1).astype('float64'))\n",
    "        return df\n",
    "\n",
    "    def _transform_continuous(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Scales non-missing values of continuous variables. Casts to\n",
    "            float64.\"\"\"\n",
    "        for col_name in self.columns['cont']:\n",
    "            if df.loc[df[col_name].notnull(), col_name].shape[0]:\n",
    "                df.loc[df[col_name].notnull(), col_name] = self.encoders[\n",
    "                    'scalers'][col_name].transform(df.loc[\n",
    "                        df[col_name].notnull(),\n",
    "                        col_name].values.reshape(-1, 1).astype('float64'))\n",
    "        return df\n",
    "\n",
    "    def _make_continuous_missingness_indicators(\n",
    "            self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"For every continous variable, makes separate indicator column for\n",
    "            each continuous variable, which is 1 where it has a missing value,\n",
    "            else 0.\"\"\"\n",
    "        for col_name in self.columns['cont']:\n",
    "            missing_indicator = df[col_name].isnull().astype(int)\n",
    "            if self.verbose:\n",
    "                n_missing = missing_indicator.sum()\n",
    "                print('{} has {} missing values.'.format(col_name, n_missing))\n",
    "            df['{}_MISSING'.format(col_name)] = missing_indicator\n",
    "        return df\n",
    "\n",
    "    def _impute_continuous_missingness(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fill in missing values for continuous variables.\"\"\"\n",
    "        df.loc[:, self.columns['cont']] = df.loc[\n",
    "            :, self.columns['cont']].fillna(self.continuous_fill_value)\n",
    "        return df\n",
    "\n",
    "    def _cast_categorical_as_str(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Casts non-missing values of categorical variables as strings, to\n",
    "            ensure consistent typing once missingness category is added.\"\"\"\n",
    "        for col_name in self.columns['cat']:\n",
    "            if df.loc[df[col_name].notnull(), col_name].shape[0]:\n",
    "                df.loc[df[col_name].notnull(), col_name] = (\n",
    "                    df.loc[df[col_name].notnull(), col_name].astype(str))\n",
    "        return df\n",
    "\n",
    "    def _add_missingness_category_for_categorical(\n",
    "            self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fill in missing values for categorical variables with a separate\n",
    "            string, that will end up being encoded as a separate category.\"\"\"\n",
    "        df.loc[:, self.columns['cat']] = df.loc[\n",
    "            :, self.columns['cat']].fillna(self.categorical_fill_value)\n",
    "        return df\n",
    "\n",
    "    def _fit_transform_all_categorical(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fits one-hot encoders for all categorical variables, then does the\n",
    "            encoding. Adds a custom .columns_ attribute to each OHE object\n",
    "            containing the corresponding DataFrame column names.\"\"\"\n",
    "        self.encoders['ohe'] = dict()\n",
    "        for col_name in self.columns['cat']:\n",
    "            ohe_var = pd.DataFrame(\n",
    "                self._fit_transform_single_categorical(df, col_name),\n",
    "                columns=self.encoders['ohe'][col_name].categories_[0])\n",
    "            ohe_var.columns = ['{}_{}'.format(\n",
    "                col_name, category.lstrip().replace(' ', '_').upper())\n",
    "                for category in ohe_var.columns]\n",
    "            self.encoders['ohe'][col_name].columns_ = list(ohe_var.columns)\n",
    "            df = pd.concat((df.drop(col_name, axis=1), ohe_var), axis=1)\n",
    "        return df\n",
    "\n",
    "    def _fit_transform_single_categorical(self, df: pd.DataFrame,\n",
    "                                          col_name: str) -> np.ndarray:\n",
    "        \"\"\"Fits a one-hot encoder then does the encoding for a single\n",
    "            categorical variable.\"\"\"\n",
    "        categories = list(df[col_name].unique())\n",
    "        if self.categorical_fill_value not in categories:\n",
    "            categories.append(self.categorical_fill_value)\n",
    "        self.encoders['ohe'][col_name] = OneHotEncoder(\n",
    "            sparse=False,\n",
    "            categories=[categories]\n",
    "        )\n",
    "        return self.encoders['ohe'][col_name].fit_transform(\n",
    "            df[col_name].values.reshape(-1, 1))\n",
    "\n",
    "    def _transform_all_categorical(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"One-hot encodes the categories for all categorical variables.\"\"\"\n",
    "        for col_name in self.columns['cat']:\n",
    "            ohe_var = pd.DataFrame(\n",
    "                self.encoders['ohe'][col_name].transform(\n",
    "                    df[col_name].values.reshape(-1, 1)),\n",
    "                columns=self.encoders['ohe'][col_name].columns_)\n",
    "            df = pd.concat((df.drop(col_name, axis=1), ohe_var), axis=1)\n",
    "        return df\n",
    "\n",
    "    def _set_x_names(self, df: pd.DataFrame):\n",
    "        \"\"\"Gets column names for features.\"\"\"\n",
    "        self.x_names = df.columns.tolist()\n",
    "        self.x_names.remove(self.y_name)\n",
    "    \n",
    "    def _set_col_i(self):\n",
    "        \"\"\"Assign index to each column.\"\"\"\n",
    "        self.col_i = {k: v for k, v in zip(self.x_names,\n",
    "                                           range(len(self.x_names)))}\n",
    "\n",
    "    def _fit_transform_y(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fits a LabelBinarizer to y column, then transforms it. Uses\n",
    "            LabelBinarizer rather than OneHotEncoder to ovoid multiple-column\n",
    "            encoding for a binary label.\"\"\"\n",
    "        self.encoders['lb'] = {self.y_name: LabelBinarizer()}\n",
    "        df[self.y_name] = self.encoders['lb'][self.y_name].fit_transform(\n",
    "            df[self.y_name].values)\n",
    "        return df\n",
    "\n",
    "    def _transform_y(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Binarizes y column.\"\"\"\n",
    "        df[self.y_name] = self.encoders['lb'][self.y_name].transform(\n",
    "            df[self.y_name].values)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {'age': '70', 'workclass': 'Federal_gov', 'education': '7th-8th',\n",
    " 'education-num': '4', 'marital_status': 'Married-spouse-absent',\n",
    " 'occupation': 'Other-service', 'relationship': 'Other-relative',\n",
    " 'race': 'Amer-Indian-Eskimo', 'sex': 'Male', 'capital_gain': '1000',\n",
    " 'capital_loss': '0', 'hours_per_week': '23', 'native_country': ' Puerto-Rico',\n",
    " 'label': '<=50K'  # dummy label, not used in prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('my_dict.pkl', 'rb')\n",
    "my_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shared(my_dict['x_test'])\n",
    "pp = my_dict['pp']\n",
    "blr = my_dict['blr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_to_dataframe(user_input: dict) -> pd.DataFrame:\n",
    "    '''Converts users' input ready for input to preprocessor. We put the dict\n",
    "        in a list so that pandas makes a dataframe with 1 row, rather than a\n",
    "        series.\n",
    "\n",
    "    Args:\n",
    "        user_input: Values inputted by user into web form.\n",
    "\n",
    "    Return:\n",
    "        Converted user input.\n",
    "    '''\n",
    "    return pd.DataFrame.from_dict([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# my_dict['pp'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'capital-gain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/lap-risk-predict-jm9hy1RE/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'capital-gain'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-e926e6d0c696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_input_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new_input is DataFrame with 1 row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-1ba610dcf9fe>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_where_label_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_continuous_missingness_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impute_continuous_missingness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-1ba610dcf9fe>\u001b[0m in \u001b[0;36m_transform_continuous\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    143\u001b[0m             float64.\"\"\"\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cont'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 df.loc[df[col_name].notnull(), col_name] = self.encoders[\n\u001b[1;32m    147\u001b[0m                     'scalers'][col_name].transform(df.loc[\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lap-risk-predict-jm9hy1RE/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lap-risk-predict-jm9hy1RE/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'capital-gain'"
     ]
    }
   ],
   "source": [
    "new_input = convert_input_to_dataframe(DATA)\n",
    "\n",
    "x_test, y_test = pp.transform(new_input)  # new_input is DataFrame with 1 row\n",
    "\n",
    "X.set_value(x_test)\n",
    "\n",
    "ppc = pm.sample_ppc(my_dict['trace_blr'], samples=1000, model=my_dict['blr'], vars=[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ppc['p'].flatten()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
